{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugador aleatorio con _Football_\n",
    "Ejemplo de jugador aleatorio para el entorno [_Football_](https://github.com/google-research/football) versión `academy_empty_goal_close`. \n",
    "\n",
    "Ejecución local: requiere instalación según [instrucciones](https://github.com/jgromero/eci2019-DRL/blob/master/ejercicio/Instrucciones%20Entorno%20Football.pdf).\n",
    "\n",
    "<!-- \n",
    "<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=F8DcgFDT9sc\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/F8DcgFDT9sc/0.jpg\" \n",
    "alt=\"IMAGE ALT TEXT HERE\" width=\"580\" border=\"3\" /></a> \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar versiones del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11_vs_11_easy_stochastic',\n",
       " '11_vs_11_hard_stochastic',\n",
       " '11_vs_11_stochastic',\n",
       " 'academy_3_vs_1_with_keeper',\n",
       " 'academy_corner',\n",
       " 'academy_counterattack_easy',\n",
       " 'academy_counterattack_hard',\n",
       " 'academy_empty_goal',\n",
       " 'academy_empty_goal_close',\n",
       " 'academy_pass_and_shoot_with_keeper',\n",
       " 'academy_run_pass_and_shoot_with_keeper',\n",
       " 'academy_run_to_score',\n",
       " 'academy_run_to_score_with_keeper',\n",
       " 'academy_single_goal_versus_lazy',\n",
       " 'test_example_multiagent']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gfootball.env import scenario_builder\n",
    "scenario_builder.all_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gfootball.env as football_env\n",
    "\n",
    "env = football_env.create_environment(\n",
    "    env_name='academy_empty_goal_close', \n",
    "    stacked=False,                           # solo estado, no pixeles \n",
    "    representation='simple115',              # solo estado, no pixeles \n",
    "    with_checkpoints=True,                   # recompensas intermedias, no solo al marcar \n",
    "    render=True)                             # mostrar graficamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorar entorno virtual\n",
    "\n",
    "En primer lugar, vamos a explorar cómo funciona este entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada estado es una tupla de 115 elementos. \n",
    "\n",
    "| Información         | Estructura           | Explicación\n",
    "| --------------------|----------------------| ----------------------\n",
    "| Posición del balón  | (x, y, z)            | \n",
    "| Dirección del balón | (x, y, z)            | \n",
    "| Control del balón   | array(3)             | (1, 0, 0): nadie, (0, 1, 0): locales, (0, 0, 1): visitantes \n",
    "| Jugador activo      | array(11)            | codificación de jugador activo en locales\n",
    "| Posiciones locales  | 11 x array(2)        | 11 posiciones (x, y) de cada jugador local\n",
    "| Movimiento locales  | 11 x array(2)        | 11 vectores de movimiento (x, y) de cada jugador local\n",
    "| Posiciones visitantes  | 11 x array(2)     | 11 posiciones (x, y) de cada jugador visitante\n",
    "| Movimiento visitantes  | 11 x array(2)     | 11 vectores de movimiento (x, y) de cada jugador visitante\n",
    "| Modo de juego       | array(7)             | codificación de modo de juego: {NormalMode, KickOffMode, GoalKickMode, FreeKickMode, CornerMode, ThrowInMode, PenaltyMode}\n",
    "\n",
    "En la modalidad `academy_empty_goal_close` solo hay **51 elementos activos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El agente puede realizar 21 acciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(115,)\n",
      "Discrete(21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[idle,\n",
       " left,\n",
       " top_left,\n",
       " top,\n",
       " top_right,\n",
       " right,\n",
       " bottom_right,\n",
       " bottom,\n",
       " bottom_left,\n",
       " long_pass,\n",
       " high_pass,\n",
       " short_pass,\n",
       " shot,\n",
       " sprint,\n",
       " release_direction,\n",
       " release_sprint,\n",
       " keeper_rush,\n",
       " release_keeper_rush,\n",
       " sliding,\n",
       " dribble,\n",
       " release_dribble]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gfootball.env import football_action_set\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "football_action_set.action_set_dict['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente aleatorio\n",
    "Implementación de un agente aleatorio que juega durante 10 episodios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0728 18:44:44.811702 140580200220480 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0728 18:44:44.812389 140580200220480 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 33, FPS: 2.8, gameFPS: 26.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 1: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 18:44:54.516603 140580200220480 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0728 18:44:54.517342 140580200220480 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 201, FPS: 20.7, gameFPS: 26.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 2: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 18:44:56.889556 140580200220480 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0728 18:44:56.890120 140580200220480 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 29, FPS: 12.2, gameFPS: 27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 3: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 18:45:01.964643 140580200220480 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0728 18:45:01.965190 140580200220480 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 94, FPS: 18.5, gameFPS: 26.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 4: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 18:45:03.779951 140580200220480 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0728 18:45:03.780517 140580200220480 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 17, FPS: 9.4, gameFPS: 27.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 5: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 18:45:07.045534 140580200220480 observation_processor.py:362] Dump \"episode_done\": count limit reached / disabled\n",
      "I0728 18:45:07.046099 140580200220480 football_env_wrapper.py:85] Episode reward: 0.00 score: [0, 0], steps: 49, FPS: 15.0, gameFPS: 26.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomensa episodio 6: 0.70\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e90a397526ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0macc_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       observation = self._convert_observations(observation,\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_wrapper.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, extra_data)\u001b[0m\n\u001b[1;32m     61\u001b[0m     ]\n\u001b[1;32m     62\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menter_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'frame'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_core.py\u001b[0m in \u001b[0;36m_retrieve_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'render'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(1, 10):\n",
    "#     env.reset()\n",
    "#     acc_reward = 0\n",
    "\n",
    "#     while True:\n",
    "#         action = env.action_space.sample()\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "#         acc_reward += reward \n",
    "    \n",
    "#         if done:\n",
    "#             break\n",
    "\n",
    "#     print(\"Recomensa episodio {:d}: {:.2f}\".format(i, acc_reward))\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desactivar _logging_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gfootball.env as football_env\n",
    "from gfootball.env import football_action_set\n",
    "env = football_env.create_environment(\n",
    "    env_name='academy_empty_goal_close', \n",
    "    stacked=False,                           # solo estado, no pixeles \n",
    "    representation='simple115',              # solo estado, no pixeles \n",
    "    with_checkpoints=True,                   # recompensas intermedias, no solo al marcar \n",
    "    render=True)       \n",
    "football_action_set.action_set_dict['default']\n",
    "import sys\n",
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=115, action_size=21, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 50\tPuntuacion media (50 anteriores): 1.94\n",
      "Episodio 100\tPuntuacion media (50 anteriores): 1.96\n",
      "Episodio 150\tPuntuacion media (50 anteriores): 1.94\n",
      "Episodio 200\tPuntuacion media (50 anteriores): 1.96\n",
      "Episodio 250\tPuntuacion media (50 anteriores): 1.92\n",
      "Episodio 300\tPuntuacion media (50 anteriores): 1.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dqn(n_episodes=300, batch_length=50, eps_start=0.01, eps_end=0.01, eps_decay=0.99):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): numero maximo de episodios de entrenamiento (n_episodios)\n",
    "        max_t (int): numero maximo de pasos por episodio (n_entrenamiento)\n",
    "        eps_start (float): valor inicial de epsilon\n",
    "        eps_end (float): valor final de epsilon\n",
    "        eps_decay (float): factor de multiplicacion (por episodio) de epsilon\n",
    "    \"\"\"\n",
    "    agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "    scores = []                        # puntuaciones de cada episodio\n",
    "    scores_window = deque(maxlen=batch_length)  # puntuaciones de los ultimos 100 episodios\n",
    "    mean_scores = []\n",
    "    eps = eps_start                    # inicializar epsilon\n",
    "    promedio = 0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        acc_reward = 0\n",
    "        while True:\n",
    "            \n",
    "            # elegir accion At con politica e-greedy\n",
    "            action = agent.act(state, eps)\n",
    "            \n",
    "            # aplicar At y obtener Rt+1, St+1\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            # almacenar <St, At, Rt+1, St+1>\n",
    "            agent.memory.add(state, action, reward, observation, done)\n",
    "            \n",
    "            # train & update\n",
    "            agent.step(state, action, reward, observation, done)\n",
    "            \n",
    "            acc_reward += reward \n",
    "            \n",
    "            if done:\n",
    "                break \n",
    "\n",
    "        scores_window.append(acc_reward)       # guardar ultima puntuacion\n",
    "        scores.append(acc_reward)              # guardar ultima puntuacion\n",
    "        eps = max(eps_end, eps_decay*eps) # reducir epsilon\n",
    "        if len(scores_window)==batch_length:\n",
    "            promedio = np.mean(scores_window) \n",
    "        mean_scores.append(promedio)\n",
    "        \n",
    "        print('\\rEpisodio {}\\tPuntuacion media (ultimos {:d}): {:.2f}'.format(i_episode, i_episode-int(i_episode/batch_length)*batch_length, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % batch_length == 0:\n",
    "            print('\\rEpisodio {}\\tPuntuacion media ({:d} anteriores): {:.2f}'.format(i_episode, batch_length, np.mean(scores_window)))\n",
    "        if len(scores_window)==batch_length and promedio >= max(mean_scores):\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "#         if np.mean(scores_window)>=1.90:\n",
    "#             print('\\nProblema resuelto en {:d} episodios!\\tPuntuacion media (ultimos {:d}): {:.2f}'.format(i_episode-50, 50, np.mean(scores_window)))\n",
    "#             torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth') # guardar pesos de agente entrenado\n",
    "#             break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Puntuacion')\n",
    "plt.xlabel('Episodio #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agente entrenado\n",
    "Implementación del agente entrenado durante 50 episodios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1\tPuntuacion media: 2.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-baf85d94900f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# aplicar At y obtener Rt+1, St+1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0macc_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       observation = self._convert_observations(observation,\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_wrapper.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, extra_data)\u001b[0m\n\u001b[1;32m     61\u001b[0m     ]\n\u001b[1;32m     62\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menter_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'frame'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_core.py\u001b[0m in \u001b[0;36m_retrieve_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       frame = np.reshape(\n\u001b[0;32m--> 205\u001b[0;31m           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m           [3, 720, 1280])\n\u001b[1;32m    207\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "scores = []                        # puntuaciones de cada episodio\n",
    "\n",
    "for i_episode in range(1, 51):\n",
    "    state = env.reset()\n",
    "    acc_reward = 0\n",
    "    while True:\n",
    "        # elegir accion At con politica e-greedy\n",
    "        action = agent.act(state, 0.0)\n",
    "\n",
    "        # aplicar At y obtener Rt+1, St+1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        acc_reward += reward\n",
    "       \n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "    scores.append(acc_reward)              # guardar ultima puntuacion\n",
    "    print('\\rEpisodio {}\\tPuntuacion media: {:.2f}'.format(i_episode, np.mean(scores)), end=\"\")\n",
    "        \n",
    "env.close()\n",
    "\n",
    "print('\\npuntuación media final: %f' %np.mean(scores))\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores, '.')\n",
    "plt.ylabel('Puntuacion')\n",
    "plt.xlabel('Episodio #')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
