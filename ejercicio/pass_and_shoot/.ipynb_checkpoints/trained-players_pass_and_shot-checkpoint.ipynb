{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11_vs_11_easy_stochastic',\n",
       " '11_vs_11_hard_stochastic',\n",
       " '11_vs_11_stochastic',\n",
       " 'academy_3_vs_1_with_keeper',\n",
       " 'academy_corner',\n",
       " 'academy_counterattack_easy',\n",
       " 'academy_counterattack_hard',\n",
       " 'academy_empty_goal',\n",
       " 'academy_empty_goal_close',\n",
       " 'academy_pass_and_shoot_with_keeper',\n",
       " 'academy_run_pass_and_shoot_with_keeper',\n",
       " 'academy_run_to_score',\n",
       " 'academy_run_to_score_with_keeper',\n",
       " 'academy_single_goal_versus_lazy',\n",
       " 'test_example_multiagent']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gfootball.env as football_env\n",
    "from gfootball.env import football_action_set\n",
    "env = football_env.create_environment(\n",
    "    env_name='academy_pass_and_shoot_with_keeper', \n",
    "    stacked=False,                           # solo estado, no pixeles \n",
    "    representation='simple115',              # solo estado, no pixeles \n",
    "    with_checkpoints=True,                   # recompensas intermedias, no solo al marcar \n",
    "    render=True)       \n",
    "football_action_set.action_set_dict['default']\n",
    "import sys\n",
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "from dqn_agent import Agent\n",
    "agent = Agent(state_size=115, action_size=21, seed=0)\n",
    "from gfootball.env import scenario_builder\n",
    "scenario_builder.all_scenarios()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 3\tPuntuacion media (ultimos 50): 1.20\n",
      "Problema resuelto en -47 episodios!\tPuntuacion media (ultimos 50): 1.20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dqn(n_episodes=1000, batch_length=50, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): numero maximo de episodios de entrenamiento (n_episodios)\n",
    "        max_t (int): numero maximo de pasos por episodio (n_entrenamiento)\n",
    "        eps_start (float): valor inicial de epsilon\n",
    "        eps_end (float): valor final de epsilon\n",
    "        eps_decay (float): factor de multiplicacion (por episodio) de epsilon\n",
    "    \"\"\"\n",
    "#     #-------------------CHECK PREVIOUS MAX SCORE----------------------#\n",
    "#     import os\n",
    "#     import re\n",
    "#     import pathlib\n",
    "\n",
    "#     path = \"/home/joaco/Desktop/joaco/ECI/DRL/eci2019-DRL-master/ejercicio/pass_and_shoot\"\n",
    "#     os.chdir(path)\n",
    "#     mediciones_path = pathlib.Path(path)\n",
    "#     med = list(mediciones_path.glob('checkpoint_score=*.pth'))\n",
    "#     print(med[0])\n",
    "#     res = re.split(r\"=\", str(med))\n",
    "#     res = re.split(r\".\", str(res[1]))\n",
    "#     print(res)\n",
    "    \n",
    "#     agent.qnetwork_local.load_state_dict(torch.load('checkpoint_score=072.pth'))\n",
    "    scores = []                        # puntuaciones de cada episodio\n",
    "    scores_window = deque(maxlen=batch_length)  # puntuaciones de los ultimos 100 episodios\n",
    "    mean_scores = []\n",
    "    eps = eps_start                    # inicializar epsilon\n",
    "    promedio = 0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        acc_reward = 0\n",
    "        while True:\n",
    "            \n",
    "            # elegir accion At con politica e-greedy\n",
    "            action = agent.act(state, eps)\n",
    "            \n",
    "            # aplicar At y obtener Rt+1, St+1\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            # almacenar <St, At, Rt+1, St+1>\n",
    "            agent.memory.add(state, action, reward, observation, done)\n",
    "            \n",
    "            # train & update\n",
    "            agent.step(state, action, reward, observation, done)\n",
    "            \n",
    "            acc_reward += reward \n",
    "            \n",
    "            if done:\n",
    "                break \n",
    "\n",
    "        scores_window.append(acc_reward)       # guardar ultima puntuacion\n",
    "        scores.append(acc_reward)              # guardar ultima puntuacion\n",
    "        eps = max(eps_end, eps_decay*eps) # reducir epsilon\n",
    "        if len(scores_window)==batch_length:\n",
    "            promedio = np.mean(scores_window) \n",
    "        mean_scores.append(promedio)\n",
    "\n",
    "        \n",
    "        print('\\rEpisodio {}\\tPuntuacion media (ultimos {:d}): {:.2f}'.format(i_episode, batch_length, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % batch_length == 0:\n",
    "            print('\\rEpisodio {}\\tPuntuacion media ({:d} anteriores): {:.2f}'.format(i_episode, batch_length, np.mean(scores_window)))\n",
    "#         if len(scores_window)==batch_length and promedio >= max(mean_scores):\n",
    "#             torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_score={}.pth'.format(promedio))\n",
    "        if len(scores_window)==batch_length and np.mean(scores_window)>=1.00:\n",
    "            print('\\nProblema resuelto en {:d} episodios!\\tPuntuacion media (ultimos {:d}): {:.2f}'.format(i_episode-50, 50, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth') # guardar pesos de agente entrenado\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Puntuacion')\n",
    "plt.xlabel('Episodio #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Agente entrenado\n",
    "Implementación del agente entrenado durante 50 episodios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 1\tPuntuacion media: 2.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-baf85d94900f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# aplicar At y obtener Rt+1, St+1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0macc_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       observation = self._convert_observations(observation,\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_wrapper.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, extra_data)\u001b[0m\n\u001b[1;32m     61\u001b[0m     ]\n\u001b[1;32m     62\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menter_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'frame'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/football/lib/python3.7/site-packages/gfootball/env/football_env_core.py\u001b[0m in \u001b[0;36m_retrieve_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       frame = np.reshape(\n\u001b[0;32m--> 205\u001b[0;31m           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m           [3, 720, 1280])\n\u001b[1;32m    207\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "scores = []                        # puntuaciones de cada episodio\n",
    "\n",
    "for i_episode in range(1, 51):\n",
    "    state = env.reset()\n",
    "    acc_reward = 0\n",
    "    while True:\n",
    "        # elegir accion At con politica e-greedy\n",
    "        action = agent.act(state, 0.0)\n",
    "\n",
    "        # aplicar At y obtener Rt+1, St+1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        acc_reward += reward\n",
    "       \n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "    scores.append(acc_reward)              # guardar ultima puntuacion\n",
    "    print('\\rEpisodio {}\\tPuntuacion media: {:.2f}'.format(i_episode, np.mean(scores)), end=\"\")\n",
    "        \n",
    "env.close()\n",
    "\n",
    "print('\\npuntuación media final: %f' %np.mean(scores))\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores, '.')\n",
    "plt.ylabel('Puntuacion')\n",
    "plt.xlabel('Episodio #')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
